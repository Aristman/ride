# ROADMAP: RAG-обогащение чата через БД эмбеддингов

Данный документ описывает внедрение Retrieval-Augmented Generation (RAG) в чат плагина: при включённой опции система выполняет поиск релевантных чанков из локальной индексированной БД эмбеддингов и дополняет ими запрос пользователя перед обращением к LLM.

Целевое поведение: при каждом запросе, если опция активна, выполняется поиск top-N релевантных фрагментов проекта и их безопасная интеграция в промпт с учётом лимитов токенов и корректной деградации при ошибках или отсутствии данных.

## Область и критерии приёмки
Функциональность RAG доступна как опциональная настройка. При включении:
- Чат обогащает запрос релевантными фрагментами из индексной БД проекта.
- Лимиты токенов соблюдаются, обогащение не ломает историю и формат ответов.
- При отсутствии БД или недоступности сервиса эмбеддингов поведение корректно деградирует без падений.
- Базовые тесты покрывают поиск, сборку промпта и деградацию.

## Параметры и UX
По умолчанию используются консервативные параметры (могут быть изменены в будущих итерациях):
- topK = 5
- similarityThreshold ≈ 0.25
- Ограничение по контексту использует существующий параметр `maxContextTokens`.
В UI достаточно одного чекбокса для включения/выключения RAG. Индикация применения RAG в сообщении — простая метка в метаданных/заголовке.

## Риски и ограничения
Возможны задержки на больших индексах, несовпадение размерностей эмбеддингов, а также превышение лимитов контекста. Предусмотрены: валидации размерностей, обрезка контента по приоритету релевантности, логирование ключевых этапов retrieval.

---

## Фазы выполнения (чек-листы)

### Фаза 1 — Конфигурация и флаг
- [ ] Добавить поле `enableRagEnrichment` в `PluginSettingsState`
- [ ] Прокинуть геттер/сеттер в `PluginSettings`
- [ ] Добавить чекбокс в `SettingsConfigurable` (вкладка будет выбрана по аналогии с существующими настройками)
- [ ] Сохранение/загрузка состояния и reset/apply в UI

### Фаза 2 — Retrieval слой (БД эмбеддингов)
- [ ] Использовать `EmbeddingDatabaseService.findSimilarEmbeddings()` для получения topK пар (chunkId, similarity)
- [ ] Получать содержимое через `getChunkById()` и формировать список кандидатов
- [ ] Фильтровать по `similarityThreshold` и отсекать шум
- [ ] Логировать ключевые этапы и параметры (topK, threshold, итоговый счётчик)

### Фаза 3 — Интеграция в обработку сообщений
- [ ] В `ChatService.sendMessage()` при включённом флаге выполнять retrieval перед обращением к LLM
- [ ] Собрать расширенный промпт: системное сообщение с правилами + блок "Retrieved context" + исходный вопрос
- [ ] Пробросить метаданные ответа: `ragEnabled`, `retrievedCount`, список источников (файл, строки)
- [ ] Минимальная интеграция с оркестратором (по необходимости — отдельной подзадачей)

### Фаза 4 — Контроль токенов и форматирование
- [ ] Оценивать длину контекста с учётом `maxContextTokens`
- [ ] Обрезать/ранжировать чанки по релевантности до безопасного размера
- [ ] Гарантировать корректный формат истории и системного промпта

### Фаза 5 — Надёжность и тестирование
- [ ] Корректная деградация при отсутствии БД/пустой выдаче/таймаутах эмбеддингов
- [ ] Юнит-тесты: ранжирование, фильтрация по similarity, сборка промпта
- [ ] Интеграционные тесты: путь без БД и с неполными данными

### Фаза 6 — Документация и UX
- [ ] Обновить `docs/` и `docs/roadmaps/README.md` при необходимости
- [ ] Описать включение RAG и процесс индексации (ссылку на уже существующий индексатор)
- [ ] Краткая заметка в README о параметрах по умолчанию и ограничениях
